Spark achieves simplicity by providing a fundamental abstraction of a simple logical data structure called a Resilient Distributed Dataset RDD upon which all other higher level structured data abstractions such as DataFrames and Datasets are constructed By providing a set of transformations and actions as operations Spark offers a simple programming model that you can use to build big data applications in familiar languages